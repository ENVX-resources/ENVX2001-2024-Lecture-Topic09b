{
  "hash": "80b0accfc0dd7e0f64cafec736649a42",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Regression: predictive modelling -- Part 2\"\nsubtitle: \"ENVX2001 - Applied Statistical Methods\"\nauthor:\n  - name: Januar Harianto\n    affiliations: The University of Sydney\ndate: last-modified\nself-contained: true\nexecute:\n  freeze: auto\n  cache: false\n# NOTE: please check _quarto.yml file for more options\n---\n\n\n\n\n\n\n\n# Recap\n\n## Model validation workflow\n\n1. **Split** the data into training and test sets (not necessary for cross-validation techniques)\n\n. . .\n  \n2. **Develop model(s)** on the training set (includes variable selection).\n\n. . .\n\n3. **Validate** the model(s) by comparing to the test set:\n   - **RMSE** - root mean squared error: a measure of accuracy.\n     - *The lower, the better*\n   - **ME** - mean error: a measure of bias.\n     - *The closer to 0, the better*\n   - **CCC** - concordance correlation coefficient: a measure of agreement/precision.\n     - *The closer to 1, the better*\n\n# Example: Loyn dataset\n\n## About\n\nData on the relationship between bird abundance (bird ha^-1^) and the characteristics of forest patches at 56 locations in SE Victoria.  \n\nThe predictor variables are:\n\n- `ALT` Altitude (m) \n- `YR.ISOL` Year when the patch was isolated (years) \n-\t`GRAZE` Grazing (coded 1-5 which is light to heavy) \n-\t`AREA` Patch area (ha) \n-\t`DIST` Distance to nearest patch (km) \n-\t`LDIST` Distance to largest patch (km)  \n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(readxl)\nloyn <- read_xlsx(\"assets/mlr.xlsx\", \"Loyn\")\n```\n:::\n\n\n\n## Dataset splitting\n\nWe will split the data into training and test sets.\n\n:::{.callout-note}\nSometimes, the training and tests sets are also called the *calibration* and *validation* sets, respectively.\n:::\n\nAs the dataset is quite small, we will use a 80:20 split.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(100)\nindexes <- sample(1:nrow(loyn), size = 0.2 * nrow(loyn))\nloyn_train <- loyn[-indexes, ] # use this to create model\nloyn_test <- loyn[indexes, ] # use this to validate model\n```\n:::\n\n\n## Checking the split\n\nHave a quick `glimpse()` of the data to see if the split worked. If your data does not look the same as below, you may have forgotten to set the seed.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nglimpse(loyn_train)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 45\nColumns: 7\n$ ABUND   <dbl> 5.3, 2.0, 1.5, 17.1, 13.8, 3.8, 2.2, 3.3, 27.6, 1.8, 21.2, 8.0…\n$ AREA    <dbl> 0.1, 0.5, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.…\n$ YR.ISOL <dbl> 1968, 1920, 1900, 1966, 1918, 1955, 1920, 1965, 1926, 1890, 19…\n$ DIST    <dbl> 39, 234, 104, 66, 246, 467, 284, 156, 66, 93, 39, 259, 130, 26…\n$ LDIST   <dbl> 39, 234, 311, 66, 246, 467, 1829, 156, 332, 93, 39, 259, 623, …\n$ GRAZE   <dbl> 2, 5, 5, 3, 5, 5, 5, 4, 3, 5, 2, 5, 5, 3, 3, 3, 2, 2, 1, 3, 3,…\n$ ALT     <dbl> 160, 60, 140, 160, 140, 90, 60, 130, 210, 160, 210, 120, 145, …\n```\n\n\n:::\n\n```{.r .cell-code}\nglimpse(loyn_test)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 11\nColumns: 7\n$ ABUND   <dbl> 3.0, 29.5, 26.0, 39.6, 34.4, 19.5, 14.6, 28.3, 15.8, 5.0, 14.1\n$ AREA    <dbl> 1, 973, 18, 49, 96, 6, 2, 34, 5, 4, 1\n$ YR.ISOL <dbl> 1900, 1970, 1966, 1972, 1976, 1890, 1972, 1965, 1965, 1923, 19…\n$ DIST    <dbl> 311, 337, 40, 1427, 39, 93, 402, 66, 39, 26, 234\n$ LDIST   <dbl> 571, 1323, 3188, 1557, 519, 226, 402, 345, 39, 2205, 285\n$ GRAZE   <dbl> 5, 1, 2, 1, 2, 3, 1, 1, 3, 5, 3\n$ ALT     <dbl> 130, 190, 190, 180, 175, 170, 210, 110, 130, 120, 130\n```\n\n\n:::\n:::\n\n\n# Model development\nFrom now on, we will work with the **training set only**.\n\n## Explore\n\n- The next step is to visualise the data.\n- Expore relationships between the predictors and the response. \n  - Histograms\n  - Correlation plots\n  - Boxplots\n\nIn this lecture we will just look at histograms.\n\n## Boxplots\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(Hmisc)\nhist(loyn_train, nclass = 20)\n```\n\n::: {.cell-output-display}\n![](Lecture-09b_files/figure-revealjs/unnamed-chunk-4-1.png){width=960}\n:::\n:::\n\n\n- Looks like `AREA` `LDIST` and `DIST` are skewed -- we will transform them so that they are more normally distributed.\n\n## Transforming predictors\n\n We will use `log10()` to transform the predictors. The `mutate()` function from the `dplyr` package is useful for this as it can create new columns in the data frame with the transformed values.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nloyn_train <- loyn_train %>%\n    mutate(\n        AREA_L10 = log10(AREA),\n        LDIST_L10 = log10(LDIST),\n        DIST_L10 = log10(DIST)\n    )\n```\n:::\n\n\nThen, remove the untransformed variables from the dataset. Here we can use the `select()` function from the `dplyr` package to \"delselect\" columns by using the `-` sign.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nloyn_train <- loyn_train %>%\n    select(-AREA, -LDIST, -DIST)\nglimpse(loyn)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 56\nColumns: 7\n$ ABUND   <dbl> 5.3, 2.0, 1.5, 17.1, 13.8, 14.1, 3.8, 2.2, 3.3, 3.0, 27.6, 1.8…\n$ AREA    <dbl> 0.1, 0.5, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.…\n$ YR.ISOL <dbl> 1968, 1920, 1900, 1966, 1918, 1965, 1955, 1920, 1965, 1900, 19…\n$ DIST    <dbl> 39, 234, 104, 66, 246, 234, 467, 284, 156, 311, 66, 93, 39, 40…\n$ LDIST   <dbl> 39, 234, 311, 66, 246, 285, 467, 1829, 156, 571, 332, 93, 39, …\n$ GRAZE   <dbl> 2, 5, 5, 3, 5, 3, 5, 5, 4, 5, 3, 5, 2, 1, 5, 5, 3, 3, 3, 2, 2,…\n$ ALT     <dbl> 160, 60, 140, 160, 140, 130, 90, 60, 130, 130, 210, 160, 210, …\n```\n\n\n:::\n:::\n\n\n## Final inspection\n\nView the histograms again to check that the transformation worked.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhist(loyn_train, nclass = 20)\n```\n\n::: {.cell-output-display}\n![](Lecture-09b_files/figure-revealjs/unnamed-chunk-7-1.png){width=960}\n:::\n:::\n\n\n## Full model\n\nWe start with a full model that includes all the predictors.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfull_fit <- lm(ABUND ~ ., data = loyn_train)\nsummary(full_fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = ABUND ~ ., data = loyn_train)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-17.3445  -3.4647   0.1991   2.8689  14.1844 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -159.27533  109.13660  -1.459   0.1527    \nYR.ISOL        0.09334    0.05392   1.731   0.0916 .  \nGRAZE         -1.40912    1.03653  -1.359   0.1820    \nALT            0.01657    0.02810   0.589   0.5590    \nAREA_L10       8.09629    1.78591   4.533 5.63e-05 ***\nLDIST_L10      2.05115    3.23927   0.633   0.5304    \nDIST_L10      -6.18596    4.83189  -1.280   0.2082    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.497 on 38 degrees of freedom\nMultiple R-squared:  0.6752,\tAdjusted R-squared:  0.6239 \nF-statistic: 13.17 on 6 and 38 DF,  p-value: 5.277e-08\n```\n\n\n:::\n:::\n\n\n## Assumptions - Round 1\n\nAs usual, we should check the assumptions of the model. We will use the `check_model()` function from the `perfomance` package as it also has VIF plots, which we will use.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(performance)\ncheck_model(full_fit)\n```\n\n::: {.cell-output-display}\n![](Lecture-09b_files/figure-revealjs/unnamed-chunk-9-1.png){width=960}\n:::\n:::\n\n\n- Overall, all the assumptions are met. VIFs are all < 10, so no multicollinearity.\n\n# Variable selection\n\n## Backwards stepwise selection\n\nUse the `step()` function perform backwards stepwise selection. This function uses AIC to select the best model. \n\n:::{.callout-note}\nDepending on the dataset splitting, the best model may be different each time we randomly sample the data. In this case we should all have the same results as we set the seed.\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstep_fit <- step(full_fit, direction = \"backward\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nStart:  AIC=174.81\nABUND ~ YR.ISOL + GRAZE + ALT + AREA_L10 + LDIST_L10 + DIST_L10\n\n            Df Sum of Sq    RSS    AIC\n- ALT        1     14.67 1618.5 173.22\n- LDIST_L10  1     16.92 1620.8 173.28\n- DIST_L10   1     69.18 1673.0 174.71\n<none>                   1603.9 174.81\n- GRAZE      1     78.00 1681.9 174.94\n- YR.ISOL    1    126.48 1730.3 176.22\n- AREA_L10   1    867.44 2471.3 192.26\n\nStep:  AIC=173.22\nABUND ~ YR.ISOL + GRAZE + AREA_L10 + LDIST_L10 + DIST_L10\n\n            Df Sum of Sq    RSS    AIC\n- LDIST_L10  1     10.76 1629.3 171.52\n<none>                   1618.5 173.22\n- DIST_L10   1     85.56 1704.1 173.54\n- GRAZE      1     98.23 1716.8 173.87\n- YR.ISOL    1    117.80 1736.3 174.38\n- AREA_L10   1   1088.05 2706.6 194.35\n\nStep:  AIC=171.52\nABUND ~ YR.ISOL + GRAZE + AREA_L10 + DIST_L10\n\n           Df Sum of Sq    RSS    AIC\n<none>                  1629.3 171.52\n- GRAZE     1     93.97 1723.3 172.04\n- YR.ISOL   1    107.73 1737.0 172.40\n- DIST_L10  1    114.60 1743.9 172.57\n- AREA_L10  1   1161.66 2791.0 193.74\n```\n\n\n:::\n:::\n\n\n- If we compare to the full model, the adjusted r-squared is slightly higher, and the AIC is lower.\n\n## The selected model\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(step_fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = ABUND ~ YR.ISOL + GRAZE + AREA_L10 + DIST_L10, data = loyn_train)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-18.1683  -3.1961   0.3374   3.4834  14.2021 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -135.17508  102.72850  -1.316    0.196    \nYR.ISOL        0.08323    0.05118   1.626    0.112    \nGRAZE         -1.50496    0.99082  -1.519    0.137    \nAREA_L10       8.61888    1.61392   5.340 3.98e-06 ***\nDIST_L10      -4.87726    2.90770  -1.677    0.101    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.382 on 40 degrees of freedom\nMultiple R-squared:  0.6701,\tAdjusted R-squared:  0.6371 \nF-statistic: 20.31 on 4 and 40 DF,  p-value: 3.365e-09\n```\n\n\n:::\n:::\n\n\n## Assumptions - Round 2\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncheck_model(step_fit)\n```\n\n::: {.cell-output-display}\n![](Lecture-09b_files/figure-revealjs/unnamed-chunk-12-1.png){width=960}\n:::\n:::\n\n\n# Model validation\nIt looks like the model is good, so let's bring in the test set to see how it performs!\n\n## Assess prediction quality\n\n- RMSE: root mean squared error\n\n$$ RMSE = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 $$\n\n- ME: mean error - also commonly called **bias**\n\n$$ ME = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i) $$\n\n\n- CCC: Lin's concordance correlation coefficient\n- We will also look at correlations (so as to compare with CCC)\n- All of these have been implemented as functions in various packages, so we can also use those.\n\n## Performing the tests\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(caret)\nlibrary(epiR)\n```\n:::\n\n\nThe following functions are available:\n\n- `RMSE()` from the `caret` package: `RMSE(y, y_hat)`\n- `epi.ccc()` from the `epiR` package: `epi.ccc(y, y_hat)`\n- `cor()` from base R: `cor(y, y_hat)`\n\nWe need to use calculations for:\n\n- ME: `mean(y - y_hat)`\n\nRecall:\n\n- full model: `full_fit`\n- stepwise model: `step_fit`\n- test data: `loyn_test`\n\n## Prepare the test data\n\nSince the test data has not been transformed, we need to do that first.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nloyn_test <- loyn_test %>%\n    mutate(\n        AREA_L10 = log10(AREA),\n        LDIST_L10 = log10(LDIST),\n        DIST_L10 = log10(DIST)\n    ) %>%\n    select(-AREA, -LDIST, -DIST)\n```\n:::\n\n\n## Perform tests (1)\n\n#### RMSE - lower is better\n\n\n::: {.cell}\n\n```{.r .cell-code}\nRMSE(loyn_train$ABUND, predict(step_fit))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 6.017196\n```\n\n\n:::\n\n```{.r .cell-code}\nRMSE(loyn_test$ABUND, predict(step_fit, newdata = loyn_test))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 6.718147\n```\n\n\n:::\n:::\n\n\n*RMSE is larger in the test set because the model was not trained on that data. Looks like the model is overfitting.*\n\n\n#### ME - lower is better\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmean(loyn_train$ABUND - predict(step_fit))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -1.421085e-15\n```\n\n\n:::\n\n```{.r .cell-code}\nmean(loyn_test$ABUND - predict(step_fit, newdata = loyn_test))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -1.654071\n```\n\n\n:::\n:::\n\n\n*ME is smaller in the training set because of the larger sample size.* \n\n\n## Perform tests (2)\n\nCorrelation - higher is better\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncor(loyn_train$ABUND, predict(step_fit))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.8185731\n```\n\n\n:::\n\n```{.r .cell-code}\ncor(loyn_test$ABUND, predict(step_fit, newdata = loyn_test))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.8226011\n```\n\n\n:::\n:::\n\n\n*Correlation is similar in both sets.*\n\nCCC - higher is better\n\n\n::: {.cell}\n\n```{.r .cell-code}\nepi.ccc(loyn_train$ABUND, predict(step_fit))$rho.c\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n        est     lower     upper\n1 0.8024397 0.6769108 0.8826113\n```\n\n\n:::\n\n```{.r .cell-code}\nepi.ccc(loyn_test$ABUND, predict(step_fit, newdata = loyn_test))$rho.c\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n        est     lower     upper\n1 0.8121518 0.4533066 0.9444561\n```\n\n\n:::\n:::\n\n\n*CCC is higher in training set, indicating that the model is overfitting.*\n\n## Conclusions\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# put all data into a tible and kable it\ntibble(\n    Dataset = c(\"Training\", \"Test\"),\n    RMSE = c(\n        RMSE(loyn_train$ABUND, predict(step_fit)),\n        RMSE(loyn_test$ABUND, predict(step_fit, newdata = loyn_test))\n    ),\n    ME = c(\n        mean(loyn_train$ABUND - predict(step_fit)),\n        mean(loyn_test$ABUND - predict(step_fit, newdata = loyn_test))\n    ),\n    COR = c(\n        cor(loyn_train$ABUND, predict(step_fit)),\n        cor(loyn_test$ABUND, predict(step_fit, newdata = loyn_test))\n    ),\n    CCC = c(\n        epi.ccc(loyn_train$ABUND, predict(step_fit))$rho.c[[1]],\n        epi.ccc(loyn_test$ABUND, predict(step_fit, newdata = loyn_test))$rho.c[[1]]\n    )\n) %>%\n    knitr::kable()\n```\n\n::: {.cell-output-display}\n\n\n|Dataset  |     RMSE|        ME|       COR|       CCC|\n|:--------|--------:|---------:|---------:|---------:|\n|Training | 6.017196|  0.000000| 0.8185731| 0.8024397|\n|Test     | 6.718147| -1.654071| 0.8226011| 0.8121518|\n\n\n:::\n:::\n\n\n- The model is overfitting, but not too badly (differences are small enough between training and test sets)\n- Large difference in ME is expected, as the training set is much larger than the test set (so the mean is more stable)\n- Overfitting indicates that model is still too complex: we should try to simplify it further.\n- This could be due to the small sample size, or the fact that we have too many predictors, or the `set.seed()` function causing the model(s) to be different each time.\n\n# Thanks!\n\n**Questions? Comments?**\n\nSlides made with [Quarto](https://quarto.org)\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}